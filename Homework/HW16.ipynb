{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "from sympy import *\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7714528937439997"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = -8\n",
    "b = 11\n",
    "i = 4\n",
    "\n",
    "r = 0.618**i*(b-a)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 5.0 h^{2} + 10 h + 10$"
      ],
      "text/plain": [
       "5.0*h**2 + 10*h + 10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 16.2\n",
    "x = Symbol('x')\n",
    "h = Symbol('h')\n",
    "x0 = 1\n",
    "f = 1*x**3 + 2*x**2 + 3*x +4\n",
    "approx = f.subs(x,x0) + diff(f,x).subs(x,x0)*h + 0.5 * diff(f,x,2).subs(x,x0)*h**2\n",
    "approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.0357142857142857$"
      ],
      "text/plain": [
       "-0.0357142857142857"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 16.4\n",
    "x0 = 0.25\n",
    "x = Symbol('x')\n",
    "f = -exp(-x**2)\n",
    "x1 = x0 - diff(f,x).subs(x,x0)/diff(f,x,2).subs(x,x0)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16.10\n",
    "def hessian(f, X):\n",
    "    x0, y0 = X[0, 0], X[1,0]\n",
    "    x, y = Symbol('x'), Symbol('y')\n",
    "    A = Matrix([f])\n",
    "    B = Matrix([x, y])\n",
    "    Hessian = A.jacobian(B).jacobian(B).subs({x:x0, y:y0})\n",
    "    return np.array(Hessian).astype(np.float64)\n",
    "\n",
    "def gradient(f, X):\n",
    "    x0, y0 = X[0, 0], X[1,0]\n",
    "    x, y = Symbol('x'), Symbol('y')\n",
    "    A = Matrix([f])\n",
    "    B = Matrix([x, y])\n",
    "    Gradient = A.jacobian(B).subs({x:x0, y:y0})\n",
    "    return np.array(Gradient).astype(np.float64).T\n",
    "\n",
    "def newtons_method(f, x_init, tol):\n",
    "    x_new = x_init\n",
    "    x_prev = np.random.randn(x_init.shape[0])\n",
    "    cnt = 0\n",
    "    while(la.norm(gradient(f, x_new)) > tol):\n",
    "        x_prev = x_new\n",
    "        print(x_prev)\n",
    "        s = -la.solve(hessian(f, x_prev), gradient(f, x_prev))\n",
    "        x_new = x_prev + s\n",
    "        print(x_new)\n",
    "        cnt += 1\n",
    "    return x_new, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]]\n",
      "[[0.11370097]\n",
      " [0.00284252]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.11370097],\n",
       "        [0.00284252]]),\n",
       " 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_init = np.array([[1],[2]])\n",
    "x, y = Symbol('x'), Symbol('y')\n",
    "f = 22 * x**2- 5 * x + 5 + 20*y**2- x*y\n",
    "tol = 1e-10\n",
    "newtons_method(f, x_init, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8],\n",
       "       [-5]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 16.11\n",
    "x, y = Symbol('x'), Symbol('y')\n",
    "f = 1.5*x**2 + 2*x*y + 2.5*y**2\n",
    "X0 = np.array([[8], [5]])\n",
    "#s0 = -la.solve(hessian(f, X0), gradient(f, X0).T)\n",
    "s0 = -X0\n",
    "s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[133.        ]\n",
      " [ 26.73016398]]\n",
      "\n",
      "[[1312.          133.        ]\n",
      " [ 133.            2.34788858]]\n",
      "[[-0.22198221]\n",
      " [ 2.18977935]]\n",
      "\n",
      "[[-133.        ]\n",
      " [ -26.73016398]]\n"
     ]
    }
   ],
   "source": [
    "# 16.12\n",
    "x, y = Symbol('x'), Symbol('y')\n",
    "f = 7*x**2 + 3*x*y + 7*y**2 + 13*exp(10*x*y) + 14*sin(y)**2 + 2*cos(x*y)\n",
    "x0 = np.array([[0], [1]])\n",
    "print(gradient(f, x0))\n",
    "print()\n",
    "print(hessian(f, x0))\n",
    "s1 = -la.solve(hessian(f, x0), gradient(f, x0))\n",
    "x1 = x0 + s1\n",
    "print(x1)\n",
    "print()\n",
    "print(-gradient(f, x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.091754  ]\n",
      " [ 0.71069289]]\n",
      "\n",
      "[[0.86237244 0.25      ]\n",
      " [0.25       0.55618622]]\n",
      "[[ 1.59546844]\n",
      " [-0.41351805]]\n",
      "\n",
      "[[ 1.19226063]\n",
      " [-0.01288472]]\n"
     ]
    }
   ],
   "source": [
    "# 16.13\n",
    "x, y = Symbol('x'), Symbol('y')\n",
    "f = 3 + x**2/8 + y**2/8 - sin(x)*cos(sqrt(2)/2*y)\n",
    "x0 = np.array([[pi/3], [pi/2/sqrt(2)]]).astype(np.float64)\n",
    "alpha = 1.581\n",
    "print(gradient(f, x0))\n",
    "print()\n",
    "print(hessian(f, x0))\n",
    "s1 = -la.solve(hessian(f, x0), gradient(f, x0))\n",
    "x1 = x0 + s1\n",
    "print(x1)\n",
    "print()\n",
    "s2 = -gradient(f, x0)\n",
    "x2 = x0 + alpha * s2\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16.14\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "brackets = []\n",
    "gs = (np.sqrt(5) - 1) / 2\n",
    "m1 = a + (1 - gs) * (b - a)\n",
    "m2 = a + gs * (b - a)\n",
    "\n",
    "# Begin your modifications below here\n",
    "f1, f2 = f(m1), f(m2)\n",
    "while b - a > 1e-5:\n",
    "    if f1>= f2:\n",
    "        a = m1\n",
    "    else:\n",
    "        b = m2\n",
    "    m1 = a + (1 - gs) * (b - a)\n",
    "    m2 = a + gs * (b - a)    \n",
    "    if f1>= f2:\n",
    "        f1 = f2\n",
    "        f2 = f(m2)\n",
    "    else:\n",
    "        f2 = f1\n",
    "        f1 = f(m1)\n",
    "    \n",
    "    brackets.append([a, m1, m2, b])\n",
    "\n",
    "# End your modifications above here\n",
    "\n",
    "# Plotting code below, no need to modify\n",
    "x = np.linspace(-10, 10)\n",
    "plt.plot(x, f(x))\n",
    "\n",
    "brackets = np.array(brackets)\n",
    "names=['a', 'm1', 'm2', 'b']\n",
    "for i in range(4):\n",
    "    plt.plot(brackets[:, i], 3*np.arange(len(brackets)), 'o-', label=names[i])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(r):\n",
    "    x, y = r\n",
    "    return np.float64(3 +((x**2)/8) + ((y**2)/8) - np.sin(x)*np.cos((2**-0.5)*y))\n",
    "\n",
    "def obj_func(alpha, x, s):\n",
    "    # code for computing the objective function at (x+alpha*s)\n",
    "    return func(x + alpha * s)\n",
    "\n",
    "def steepest_descent(f, x_init, tol):\n",
    "    x_new = x_init\n",
    "    x_prev = np.random.randn(x_init.shape[0])\n",
    "    while(la.norm(x_prev - x_new, 2) > tol):\n",
    "        x_prev = x_new\n",
    "        s = -gradient(f, x_prev)\n",
    "        alpha = opt.minimize_scalar(obj_func, args=(x_prev, s)).x\n",
    "        x_new = x_prev + alpha*s\n",
    "\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:[[ 0.091754  ]\n",
      " [-0.71069289]]\n",
      "alpha:1.5810402265646062\n",
      "x_new:[[ 1.19226432]\n",
      " [-0.01291331]]\n",
      "s:[[0.07147531]\n",
      " [0.00922782]]\n",
      "alpha:0.8462419361003177\n",
      "x_new:[[ 1.25274973]\n",
      " [-0.00510434]]\n",
      "s:[[-0.00047774]\n",
      " [ 0.00370025]]\n",
      "alpha:1.3647102624709635\n",
      "x_new:[[ 1.25209775e+00]\n",
      " [-5.45660557e-05]]\n",
      "s:[[3.06504156e-04]\n",
      " [3.95506775e-05]]\n",
      "alpha:0.8389914118301472\n",
      "x_new:[[ 1.25235490e+00]\n",
      " [-2.13833769e-05]]\n",
      "s:[[-1.99968171e-06]\n",
      " [ 1.55000031e-05]]\n",
      "alpha:1.364933486946003\n",
      "x_new:[[ 1.25235217e+00]\n",
      " [-2.26903591e-07]]\n",
      "s:[[1.27492010e-06]\n",
      " [1.64473755e-07]]\n",
      "alpha:0.8384790778699812\n",
      "x_new:[[ 1.25235324e+00]\n",
      " [-8.89957885e-08]]\n",
      "s:[[-7.57729302e-09]\n",
      " [ 6.45096662e-08]]\n",
      "alpha:1.579814012086196\n",
      "x_new:[[1.25235323e+00]\n",
      " [1.29174860e-08]]\n"
     ]
    }
   ],
   "source": [
    "x, y = Symbol('x'), Symbol('y')\n",
    "f = 3 + x**2/8 + y**2/8 - sin(x)*cos(sqrt(2)/2*y)\n",
    "x_init = np.array([[pi/3], [pi/2/sqrt(2)]]).astype(np.float64)\n",
    "x_new = x_init\n",
    "x_prev = np.random.randn(x_init.shape[0])\n",
    "while(la.norm(x_prev - x_new, 2) > 1e-6):\n",
    "    x_prev = x_new\n",
    "    \n",
    "    s = -gradient(f, x_prev)\n",
    "    print('s:%s'%s)\n",
    "    alpha = np.float64(opt.minimize_scalar(obj_func, args=(x_prev, s)).x)\n",
    "    print('alpha:%s'%alpha)\n",
    "    x_new = x_prev + alpha*s\n",
    "    print('x_new:%s'%x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6789179719752454"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sympy import *\n",
    "import numpy.linalg as la\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def func(r):\n",
    "    x, y = r\n",
    "    return np.float64(3 +((x**2)/8) + ((y**2)/8) - np.sin(x)*np.cos((2**-0.5)*y))\n",
    "\n",
    "def obj_func(alpha, x, s):\n",
    "    # code for computing the objective function at (x+alpha*s)\n",
    "    return func(x + alpha * s)\n",
    "\n",
    "def steepest_descent(f, x_init, tol):\n",
    "    x_new = x_init\n",
    "    x_prev = np.random.randn(x_init.shape[0])\n",
    "    cnt = -1\n",
    "    error = la.norm(x_prev - x_new, 2)\n",
    "    xs = [x_new]\n",
    "    while(error > tol):\n",
    "        x_prev = x_new\n",
    "        s = -gradient(f, x_prev)\n",
    "        alpha = opt.minimize_scalar(obj_func, args=(x_prev, s)).x\n",
    "        x_new = x_prev + alpha*s\n",
    "        cnt += 1\n",
    "        error = la.norm(x_prev - x_new, 2)\n",
    "        xs.append(x_new)\n",
    "        \n",
    "    return x_new.flatten(), cnt, np.array(xs).reshape(-1, 2)\n",
    "\n",
    "def hessian(f, X):\n",
    "    x0, y0 = X[0, 0], X[1,0]\n",
    "    x, y = Symbol('x'), Symbol('y')\n",
    "    A = Matrix([f])\n",
    "    B = Matrix([x, y])\n",
    "    Hessian = A.jacobian(B).jacobian(B).subs({x:x0, y:y0})\n",
    "    return np.array(Hessian).astype(np.float64)\n",
    "\n",
    "def gradient(f, X):\n",
    "    x0, y0 = X[0, 0], X[1,0]\n",
    "    x, y = Symbol('x'), Symbol('y')\n",
    "    A = Matrix([f])\n",
    "    B = Matrix([x, y])\n",
    "    Gradient = A.jacobian(B).subs({x:x0, y:y0})\n",
    "    return np.array(Gradient).astype(np.float64).T\n",
    "\n",
    "def newtons_method(f, x_init, tol):\n",
    "    x_new = x_init\n",
    "    x_prev = np.random.randn(x_init.shape[0])\n",
    "    cnt = -1\n",
    "    error = la.norm(x_prev - x_new, 2)\n",
    "    xs = [x_new]\n",
    "    while(error > tol):\n",
    "        x_prev = x_new\n",
    "        s = -la.solve(hessian(f, x_prev), gradient(f, x_prev))\n",
    "        x_new = x_prev + s\n",
    "        cnt += 1\n",
    "        error = la.norm(x_prev - x_new, 2)\n",
    "        xs.append(x_new)\n",
    "    return x_new.flatten(), cnt, np.array(xs).reshape(-1, 2)\n",
    "\n",
    "x, y = Symbol('x'), Symbol('y')\n",
    "f = 3 + x**2/8 + y**2/8 - sin(x)*cos(sqrt(2)/2*y)\n",
    "x_init = r_init.reshape((2,1))\n",
    "r_newton, iteration_count_newton, rs_newton = newtons_method(f, x_init, stop)\n",
    "r_sd, iteration_count_sd, rs_sd = steepest_descent(f, x_init, stop)\n",
    "print(r_newton, r_sd, rs_newton)\n",
    "print(rs_newton.reshape(-1, 2))\n",
    "errors_newton = rs_newton - r_newton.reshape(1, 2)\n",
    "errors_newton = errors_newton[:-1,:]\n",
    "print(errors_newton, iteration_count_newton)\n",
    "newton_list= []\n",
    "for i in range(errors_newton.shape[0]):\n",
    "    newton_list.append(np.log(la.norm(errors_newton[i,:], 2)))\n",
    "print(newton_list)\n",
    "\n",
    "errors_sd = rs_sd - r_sd.reshape(1, 2)\n",
    "errors_sd = errors_sd[:-1,:]\n",
    "sd_list= []\n",
    "for i in range(errors_sd.shape[0]):\n",
    "    sd_list.append(np.log(la.norm(errors_sd[i,:], 2)))\n",
    "plt.plot(np.arange(iteration_count_newton + 1), np.array(newton_list), label = 'Newton method line')\n",
    "plt.plot(np.arange(iteration_count_sd + 1), np.array(sd_list), label = 'Steepest descent line')\n",
    "plt.legend()\n",
    "plt.title('Error vs. Iterations')\n",
    "plt.xlabel('Iteration count')\n",
    "plt.ylabel('Error')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16.16\n",
    "import numpy as np\n",
    "from sympy import *\n",
    "\n",
    "# complete the function below\n",
    "def dfunc(x):\n",
    "    # Add your code here\n",
    "    y = Symbol('y')\n",
    "    f = -exp(-y**2) * (y + sin(y))\n",
    "    return diff(f,y).subs(y,x)\n",
    "    \n",
    "\n",
    "# complete the function below\n",
    "def d2func(x):\n",
    "    # Add your code here\n",
    "    y = Symbol('y')\n",
    "    f = -exp(-y**2) * (y + sin(y))\n",
    "    return diff(f,y,2).subs(y,x)\n",
    "\n",
    "# run Newton's Method\n",
    "newton_list = [x0]\n",
    "x = x0\n",
    "while abs(dfunc(x)) > tol:\n",
    "    x -= dfunc(x)/d2func(x)\n",
    "    newton_list.append(x)\n",
    "newton_guesses = np.array(newton_list).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW 16.15\n",
    "\n",
    "from math import sin, cos\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import sympy as sp\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f(alpha, r, s):\n",
    "    r += s*alpha\n",
    "    x, y = r\n",
    "    return 3 +((x**2)/8) + ((y**2)/8) - np.sin(x)*np.cos((2**-0.5)*y)\n",
    "\n",
    "def sd_nd_optimization_crude_step(formula, symbols, x_prev):\n",
    "    x_prev = list(x_prev)\n",
    "    neg_gradient_at = -1 * np.array(gradient(formula, symbols, values=x_prev))\n",
    "    alpha = opt.minimize_scalar(f, args=(x_prev, neg_gradient_at)).x\n",
    "    return np.array(x_prev) + alpha * neg_gradient_at, la.norm(neg_gradient_at, 2)\n",
    "\n",
    "def gradient(formula, symbols, values=None):\n",
    "    '''\n",
    "    Given a SymPy formula and variables\n",
    "    Find its analytic gradient without substituion\n",
    "    as a list of SymPy formulae or numerical gradient\n",
    "    if values specified\n",
    "    '''\n",
    "    size = len(symbols)\n",
    "    gradient = []\n",
    "    for i in range(size):\n",
    "        gradient.append(formula.diff(symbols[i]))\n",
    "        \n",
    "    if values == None:\n",
    "        return gradient\n",
    "\n",
    "    # Make sure you don't mess up the analytical gradient\n",
    "    g_copy = gradient.copy()\n",
    "    gradient_at = []\n",
    "    for i in range(len(g_copy)):\n",
    "        for j in range(len(symbols)):\n",
    "            g_copy[i] = g_copy[i].subs(symbols[j], values[j])\n",
    "        gradient_at.append(float(g_copy[i].evalf()))\n",
    "    return gradient_at\n",
    "\n",
    "def subs_all(formula, variables, values):\n",
    "    '''\n",
    "    You know what, it's getting to the point where this function\n",
    "    is necessary\n",
    "    '''\n",
    "    result = formula\n",
    "    for i in range(len(values)):\n",
    "        result = result.subs(variables[i], values[i])\n",
    "    return float(result.evalf())\n",
    "\n",
    "def hessian(gradient, symbols, values=None):\n",
    "    '''\n",
    "    Given an analytic gradient and variables\n",
    "    Calculate its analytic Hessian\n",
    "    or numerical Hessian if values are specified\n",
    "    '''\n",
    "    size = len(symbols)\n",
    "    hessian = []\n",
    "    for i in range(size):\n",
    "        hessian.append([0]*size)\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            hessian[i][j] = gradient[i].diff(symbols[j])\n",
    "            \n",
    "    if values == None:\n",
    "        return hessian\n",
    "    \n",
    "    hessian_at = hessian.copy()\n",
    "    size = len(hessian)\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            hessian_at[i][j] = subs_all(hessian_at[i][j], symbols, [float(v) for v in values])\n",
    "#             for k in range(len(symbols)):\n",
    "#                 hessian_at[i][j] = hessian_at[i][j].subs(symbols[k], values[k])\n",
    "#             hessian_at[i][j] = float(hessian_at[i][j].evalf())\n",
    "    return hessian_at\n",
    "\n",
    "def newton_nd_optimization_crude_step(formula, symbols, x_prev):\n",
    "    x_prev = list(x_prev)\n",
    "    grad = gradient(formula, symbols)\n",
    "    neg_gradient_at = -1 * np.array(gradient(formula, symbols, values=x_prev))\n",
    "    hes_at = np.array(hessian(grad, symbols, values=x_prev))\n",
    "    return np.array(x_prev) + la.solve(hes_at, neg_gradient_at), la.norm(neg_gradient_at, 2)\n",
    "\n",
    "def newton_nd_optimization_crude(f_str, s_str, start, tolerance):\n",
    "    '''\n",
    "    A crude version of Newton ND Optimization algorithm\n",
    "    Maybe you can help out implementing an analytic solution\n",
    "    Returning the numerical solution as well as the number of\n",
    "    iterations it took\n",
    "    '''\n",
    "    x_list = []\n",
    "    formula = sp.sympify(f_str)\n",
    "    symbols = sp.symbols(s_str)\n",
    "    curr = np.copy(start)\n",
    "    iterations = 0\n",
    "    gradient = np.inf\n",
    "    while (gradient > tolerance):\n",
    "        x_list.append(curr)\n",
    "        curr, gradient = newton_nd_optimization_crude_step(formula, symbols, curr)\n",
    "        _, gradient = newton_nd_optimization_crude_step(formula, symbols, curr)\n",
    "        iterations += 1\n",
    "    x_list.append(curr)\n",
    "    return curr, iterations, x_list\n",
    "\n",
    "def sd_nd_optimization_crude(f_str, s_str, start, tolerance):\n",
    "    formula = sp.sympify(f_str)\n",
    "    symbols = sp.symbols(s_str)\n",
    "    curr = np.copy(start)\n",
    "    iterations = 0\n",
    "    gradient = np.inf\n",
    "    x_list = []\n",
    "    while (gradient > tolerance):\n",
    "        x_list.append(curr)\n",
    "        curr, gradient = sd_nd_optimization_crude_step(formula, symbols, curr)\n",
    "        iterations += 1\n",
    "    x_list.append(curr)\n",
    "    return curr, iterations, x_list\n",
    "\n",
    "\n",
    "r_newton, iteration_count_newton, newton_list = newton_nd_optimization_crude(f_str = '3 +((x**2)/8) + ((y**2)/8) - sin(x)*cos((2**-0.5)*y)', \n",
    "                                                                s_str = 'x y', \n",
    "                                                                start = r_init, \n",
    "                                                                tolerance = stop)\n",
    "\n",
    "r_sd, iteration_count_sd, sd_list = sd_nd_optimization_crude(f_str = '3 +((x**2)/8) + ((y**2)/8) - sin(x)*cos((2**-0.5)*y)', \n",
    "                                                    s_str = 'x y', \n",
    "                                                    start = r_init, \n",
    "                                                    tolerance = stop*10)\n",
    "\n",
    "\n",
    "newton_plot = [np.log(la.norm(r-r_newton,2)) for r in newton_list]\n",
    "sd_plot = [np.log(la.norm(r-r_sd,2)) for r in sd_list]\n",
    "\n",
    "plt.plot(sd_plot, label='Steepest descent line')\n",
    "plt.plot(newton_plot, label='newton')\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log(Error)')\n",
    "plt.legend()\n",
    "plt.title('Error vs. Iteration')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
